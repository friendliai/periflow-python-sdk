# The name of experiment
experiment: huggingface-mlm

# The name of job
name: mlm-run

# The name of vm type
vm: azure-16gb-v100-2g-eastus-spot

# The number of GPU devices
num_devices: 2

# Configure your job!
job_setting:
  type: custom

  # Docker config
  docker:
    # Docker image you want to use in the job
    image: friendliai/periflow:sdk
    # Bash shell command to run the job
    command: >
      cd /workspace/bert_masked_language_modeling && pip install -r requirements.txt && torchrun --nnodes $NUM_NODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port 6000 --nproc_per_node $NPROC_PER_NODE run_mlm.py \
        --config_name roberta-base \
        --tokenizer_name roberta-base \
        --dataset_name wikitext \
        --dataset_config_name wikitext-2-raw-v1 \
        --per_device_train_batch_size 8 \
        --per_device_eval_batch_size 8 \
        --do_train \
        --do_eval \
        --cache_dir /workspace/data/wikitext \
        --output_dir /workspace/ckpt \
        --max_steps 10000
  # Path to mount your workspace volume
  workspace:
    mount_path: /workspace

# Checkpoint config
checkpoint:
  # Path to output checkpoint
  output_checkpoint_dir: /workspace/ckpt

# Configuration dataset
data:
  name: wikitext
  mount_path: /workspace/data
  