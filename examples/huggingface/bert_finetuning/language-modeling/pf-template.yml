# The name of experiment
experiment: huggingface-mlm

# The name of job
name: mlm-run

# The name of vm type
vm: azure-16gb-v100-2g-eastus-spot

# The number of GPU devices
num_devices: 2

# Configure your job!
job_setting:
  type: custom

  # Docker config
  docker:
    # Docker image you want to use in the job
    image: friendliai/periflow:sdk
    # Bash shell command to run the job
    command: >
      cd /workspace/language-modeling && pip install -r requirements.txt && torchrun --nnodes $NUM_NODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port 6000 --nproc_per_node $NPROC_PER_NODE run_mlm.py \
        --model_name_or_path bert-base-cased \
        --dataset_name wikitext \
        --dataset_config_name wikitext-2-raw-v1 \
        --max_seq_length 512 \
        --output_dir /workspace/ckpt \
        --do_train \
        --max_steps 100 \
        --save_steps 100 \
        --logging_steps 10 \
        --cache_dir /workspace/data/wikitext \
        --logging_dir /workspace/runs
  # Path to mount your workspace volume
  workspace:
    mount_path: /workspace

# Checkpoint config
checkpoint:
  # Path to output checkpoint
  output_checkpoint_dir: /workspace/ckpt

# Configuration dataset
data:
  name: wikitext
  mount_path: /workspace/data
